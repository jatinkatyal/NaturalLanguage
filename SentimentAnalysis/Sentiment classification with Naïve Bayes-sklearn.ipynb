{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9fc0c2-d1f9-4dcf-beab-703a6c92e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just some imports to be used later\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf1d24-3368-4873-81b7-b81113cd35eb",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29ce78f-d0ab-4211-a881-6c9556127371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mcdonalds-store-reviews.zip to D:\\Work\\Learning\\NaturalLanguage\\SentimentAnalysis\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.78M [00:00<?, ?B/s]\n",
      " 56%|#####6    | 1.00M/1.78M [00:00<00:00, 3.92MB/s]\n",
      "100%|##########| 1.78M/1.78M [00:00<00:00, 2.56MB/s]\n",
      "100%|##########| 1.78M/1.78M [00:00<00:00, 2.72MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Get dataset\n",
    "!kaggle datasets download \"nelgiriyewithana/mcdonalds-store-reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce537c9-9c69-41a3-bec0-afb8a9b8a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "with ZipFile('mcdonalds-store-reviews.zip','r') as zipped_file:\n",
    "    zipped_file.extractall()\n",
    "\n",
    "# Delete the zipfile\n",
    "os.remove('mcdonalds-store-reviews.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebc6d02-e6e9-4f9c-b2b4-2f53a5e9a2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My mc. Crispy chicken sandwich was �����������...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  Why does it look like someone spit on my food?...       1\n",
       "1  It'd McDonalds. It is what it is as far as the...       4\n",
       "2  Made a mobile order got to the speaker and che...       1\n",
       "3  My mc. Crispy chicken sandwich was �����������...       5\n",
       "4  I repeat my order 3 times in the drive thru, a...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset\n",
    "dataset = pd.read_csv('McDonald_s_Reviews.csv',encoding_errors='ignore')\n",
    "\n",
    "#drop columns\n",
    "dataset = dataset[['review','rating']].copy()\n",
    "\n",
    "# change star ratings to integer\n",
    "dataset['rating'] = dataset['rating'].apply(lambda x: int(x.split()[0]))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795e255a-7253-4437-884f-71fa2cb26b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My mc. Crispy chicken sandwich was �����������...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  Sentiment\n",
       "0  Why does it look like someone spit on my food?...          0\n",
       "1  It'd McDonalds. It is what it is as far as the...          1\n",
       "2  Made a mobile order got to the speaker and che...          0\n",
       "3  My mc. Crispy chicken sandwich was �����������...          1\n",
       "4  I repeat my order 3 times in the drive thru, a...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop ratings with no reviews\n",
    "no_rev = list(dataset.index[dataset['review'].isna()])\n",
    "dataset = dataset.drop(no_rev)\n",
    "\n",
    "# drop neutral 3 star reviews\n",
    "ratings_3star = list(dataset.index[dataset['rating']==3])\n",
    "dataset = dataset.drop(ratings_3star)\n",
    "\n",
    "#chnage rating to label, 1: positive and 0:negative\n",
    "dataset['Sentiment'] = dataset['rating'].apply(lambda x: 1 if x>3 else 0)\n",
    "dataset = dataset[['review','Sentiment']].copy()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0bcf2-87c5-492a-b2ab-37cfd696e756",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0a7501-60eb-42d7-8d7a-cf080c2aef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(ipString,tokenizer,stopwords,lemmatizer):\n",
    "    #preprocessing\n",
    "    op = ipString.lower()\n",
    "    op = tokenizer.tokenize(op)\n",
    "    op = [token for token in op if token not in stopwords]\n",
    "    op = [lemmatizer.lemmatize(token) for token in op]\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596ba80e-837a-472f-a47d-3619755b98f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[look, like, someone, spit, food, ?, normal, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[', mcdonalds, ., far, food, atmosphere, go, ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[made, mobile, order, got, speaker, checked, ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mc, ., crispy, chicken, sandwich, �����������...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[repeat, order, 3, time, drive, thru, ,, still...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  Sentiment\n",
       "0  [look, like, someone, spit, food, ?, normal, t...          0\n",
       "1  [', mcdonalds, ., far, food, atmosphere, go, ....          1\n",
       "2  [made, mobile, order, got, speaker, checked, ....          0\n",
       "3  [mc, ., crispy, chicken, sandwich, �����������...          1\n",
       "4  [repeat, order, 3, time, drive, thru, ,, still...          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "dataset['review'] = dataset['review'].apply(lambda review: preprocessing(review, tokenizer, stopwords, lemmatizer))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5be05-5bfd-48da-8a6a-65ea2ddc63fc",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "397b6ba2-7c43-4d45-a4bd-2127f4d555b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should only use training data to generate learning features\n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f770ed-1040-449c-ba52-8e6adabb6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train['review'].apply(lambda tokens: ' '.join(tokens)))\n",
    "X_test = vectorizer.transform(test['review'].apply(lambda tokens: ' '.join(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe97c1-38e1-4e25-b178-4421e42cdcc3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df9f877-abb3-455b-b21b-50eb6ad005a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train,train['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f0e828-903e-407e-b1bc-64232cedc3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      8760\n",
      "           1       0.92      0.94      0.93     11239\n",
      "\n",
      "    accuracy                           0.92     19999\n",
      "   macro avg       0.92      0.92      0.92     19999\n",
      "weighted avg       0.92      0.92      0.92     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_train = classifier.predict(X_train)\n",
    "print('Training results')\n",
    "print(classification_report(train['Sentiment'],preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be16a74-c67b-41ca-b3d3-470aa0f13485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      3755\n",
      "           1       0.91      0.92      0.91      4817\n",
      "\n",
      "    accuracy                           0.90      8572\n",
      "   macro avg       0.90      0.90      0.90      8572\n",
      "weighted avg       0.90      0.90      0.90      8572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_test = classifier.predict(X_test)\n",
    "print('Testing results')\n",
    "print(classification_report(test['Sentiment'],preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4a550-3906-4616-b13c-538553ae30b5",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd0a7f5-94d7-487f-9d0a-91cadc7c55ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hated the food here, it is so bad that I will never come back.\tis\tnegative\n",
      "It is so good, i go there every week.\tis\tpositive\n"
     ]
    }
   ],
   "source": [
    "inferenceStrings = ['I hated the food here, it is so bad that I will never come back.', 'It is so good, i go there every week.']\n",
    "preprocessedinferenceStrings = [' '.join(preprocessing(inferenceString,tokenizer,stopwords,lemmatizer)) for inferenceString in inferenceStrings]\n",
    "X_inference = vectorizer.transform(preprocessedinferenceStrings)\n",
    "preds_inference = classifier.predict(X_inference)\n",
    "for i in range(len(inferenceStrings)):\n",
    "    print(f'{inferenceStrings[i]}\\tis\\t{\"positive\" if preds_inference[i]>0 else \"negative\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
