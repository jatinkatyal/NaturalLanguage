{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d90b698-7cef-4103-a5af-cafbb4992794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim: Scrape data from Wikipedia to create a text corpus\n",
    "# Process:\n",
    "# Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f992580c-8e92-43d7-ae28-9818ef7a49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4d15fd-4bec-47e3-957e-d5ac8e5cc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiCategoryDataScrapper:\n",
    "    def __init__(self, url, articlePrefix):\n",
    "        self.categoryURL = url\n",
    "        self.articlePrefix = prefix\n",
    "        self.categoryPageSoup = self.soup(self.request(self.categoryURL))\n",
    "        self.index = self.letterIndices()\n",
    "        self.meta = {}\n",
    "        print('Identifying articles to scrape.')\n",
    "        for letter in tqdm(self.index.keys()):\n",
    "            self.meta[letter] = self.letterLinks(letter)\n",
    "    \n",
    "    def request(self,url):\n",
    "        response = requests.get(url)\n",
    "        return response\n",
    "\n",
    "    def soup(self, response):\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup\n",
    "    \n",
    "    def letterIndices(self):\n",
    "        index = {}\n",
    "        soups = self.categoryPageSoup.body.find(id='mw-pages').find(class_='CategoryIndex').find_all('li')[2:]\n",
    "        for soup in soups:\n",
    "            index[soup.text] = soup.a['href']\n",
    "        return index\n",
    "    \n",
    "    def letterLinks(self,letter):\n",
    "        letterResponse = self.request(self.index[letter])\n",
    "        letterSoup = self.soup(letterResponse).body.find(class_='mw-category-group')\n",
    "        articles =  {}\n",
    "        articleSoups = letterSoup.find_all('li')\n",
    "        for articleSoup in articleSoups:\n",
    "            articles[articleSoup.text] = self.articlePrefix + articleSoup.a['href']\n",
    "        return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade136d-27f0-4fbf-868a-cc55b0758b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying articles to scrape.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 22/26 [00:13<00:02,  1.73it/s]"
     ]
    }
   ],
   "source": [
    "url = 'https://fr.wikipedia.org/w/index.php?title=Cat%C3%A9gorie:Portail:Robotique/Articles_li%C3%A9s&pageuntil=Essaim+de+drones#mw-pages'\n",
    "prefix = 'https://fr.wikipedia.org'\n",
    "scrapper = WikiCategoryDataScrapper(url,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64720d-06d8-45a7-b784-9809cf3e8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper.meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
